{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c66f00",
   "metadata": {},
   "source": [
    "## Sklearn MME W/ Boto3 SDK\n",
    "\n",
    "Deployment of pre-trained Sklearn models on SageMaker Multi-Model Endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d866c2d6",
   "metadata": {},
   "source": [
    "### Local Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "#Load data\n",
    "boston = datasets.load_boston()\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['MEDV'] = boston.target \n",
    "\n",
    "#Split Model\n",
    "X = df.drop(['MEDV'], axis = 1) \n",
    "y = df['MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9363f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Creation\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "with open('model.joblib', 'wb') as f:\n",
    "    joblib.dump(lm,f)\n",
    "\n",
    "\n",
    "with open('model.joblib', 'rb') as f:\n",
    "    predictor = joblib.load(f)\n",
    "\n",
    "print(\"Testing following input: \")\n",
    "print(X_test[0:1])\n",
    "sampInput = [[0.09178, 0.0, 4.05, 0.0, 0.51, 6.416, 84.1, 2.6463, 5.0, 296.0, 16.6, 395.5, 9.04]]\n",
    "print(type(sampInput))\n",
    "print(predictor.predict(sampInput))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb2447",
   "metadata": {},
   "source": [
    "### Inference Script Creation for Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5290168",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile inference.py\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == 'application/json':\n",
    "        request_body = json.loads(request_body)\n",
    "        inpVar = request_body['Input']\n",
    "        return inpVar\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned array from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    res = int(prediction[0])\n",
    "    respJSON = {'Output': res}\n",
    "    return respJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739694c0",
   "metadata": {},
   "source": [
    "### Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess\n",
    "\n",
    "\n",
    "#Setup\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "boto_session = boto3.session.Session()\n",
    "s3 = boto_session.resource('s3')\n",
    "region = boto_session.region_name\n",
    "print(region)\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b55c85",
   "metadata": {},
   "source": [
    "### Create Tar Balls\n",
    "\n",
    "This is slightly different than single model endpoints. Your model will expect the inference.py in a different tarball as MME has one inference.py script. We will tar the model artifact/data and inference script in different tarballs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050492be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build tar file with model data + inference code\n",
    "bashCommand = \"tar -cvpzf model.tar.gz model.joblib\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a separate tar file with inference code\n",
    "bashCommand = \"tar -cvpzf source.tar.gz inference.py\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06594aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bucket for model artifacts\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "print(default_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a0b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "#make 5 copies of the model.tar for MME\n",
    "s3_bucket='default-bucket'\n",
    "\n",
    "for i in {0..5}\n",
    "do\n",
    "  aws s3 cp model.tar.gz s3://$s3_bucket/key-name/sklearn-$i.tar.gz \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ba7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'bucket path to your source tar file with your inference.py code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket='sagemaker-us-east-1-474422712127'\n",
    "model_url = 's3://{}/key-name/'.format(s3_bucket) ## MODEL S3 URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {model_url} #verify that all 6 copies are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dd77a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve sklearn image\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=region,\n",
    "    version=\"0.23-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3d6f22",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f552aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "model_name = 'mme-source' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "print('Model name: ' + model_name)\n",
    "print('Model data Url: ' + model_url)\n",
    "\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            \"Image\": image_uri,\n",
    "            \"Mode\": \"MultiModel\",\n",
    "            \"ModelDataUrl\": model_url,\n",
    "            \"Environment\": {'SAGEMAKER_SUBMIT_DIRECTORY': source_dir,\n",
    "                           'SAGEMAKER_PROGRAM': 'inference.py'} \n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14427950",
   "metadata": {},
   "source": [
    "### Endpoint Config Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: EPC Creation\n",
    "sklearn_epc_name = \"mme-source\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"sklearnvariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.c5.large\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1dd0af",
   "metadata": {},
   "source": [
    "### Endpoint Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: EP Creation\n",
    "endpoint_name = \"mme-source\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monitor creation\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137427b1",
   "metadata": {},
   "source": [
    "## Invoke Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5eee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "runtime_client = boto3.client('sagemaker-runtime')\n",
    "content_type = \"application/json\"\n",
    "request_body = {\"Input\": [[0.09178, 0.0, 4.05, 0.0, 0.51, 6.416, 84.1, 2.6463, 5.0, 296.0, 16.6, 395.5, 9.04]]}\n",
    "data = json.loads(json.dumps(request_body))\n",
    "payload = json.dumps(data)\n",
    "endpoint_name = \"mme-source2022-07-11-18-01-02\"\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=content_type,\n",
    "    TargetModel = \"sklearn-5.tar.gz\",\n",
    "    Body=payload)\n",
    "result = json.loads(response['Body'].read().decode())['Output']\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
